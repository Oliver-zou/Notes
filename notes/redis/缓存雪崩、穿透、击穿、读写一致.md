<!-- GFM-TOC -->
* [缓存](#缓存)
* [缓存雪崩](#缓存雪崩)
* [缓存穿透](#缓存穿透)
* [缓存预热](#缓存预热)
* [缓存降级](#缓存降级)
* [缓存爆满](#缓存爆满)
* [网卡打满](#网卡打满)


<!-- GFM-TOC -->

## 缓存

在高并发的场景下，直接用数据库去抗是远远不够的，不管数据库是mysql还是oracle，用SSD还是磁盘阵列，采用怎样的分表分库都是很容易达到极限的，单机上千的QPS已经是一个比较的现实的天花板，而且成本太高了。而且有些比较复杂的场景单纯的去采用数据库是不能实现要求的，例如：

- 读多写少的场景，这种其实很尴尬的，数据库是力不从心 鞭长莫及。

比如文章流量：每日上亿的pv，每篇文章都会被大量的阅读，一次的insert的文章在短时间内会带来几百万甚至上千万的select。如果每次的阅读这种不善变的都直接干到数据库其实很傻的，数据库是为了记录数据不是为了这种简单查询场景设计的，这种场景下数据很容易撂挑子的。

- 需要复杂的计算得出的数据，数据库真的压力山大了。

比如排行榜：最新来访的排行，用数据库是可以实现的，大不了每次登陆或者刷新都来update一下数据么，可是当用户量过大的时候呢？看似update一个简单的数据因为量太大可能会导致整体数据库系统的瘫痪。

又比如附近的人：每个人都可能在移动这个update太频繁，mysql是可以通过插件实现这个功能，但是效率呢？

缓存就是为了应对这些场景应用而生的，诞生于高并发的互联网场景，为高速而生。也许它不能保证数据的100%的准确，也许它不能完全脱离数据库，但那些不是缓存要考虑的，它为了抗住高并发，有限的有损抗住流量洪峰，准确性可以异步慢慢操作。

缓存绝大多数存放在内存中(cpu的M1，M2，M3 cache其实也是缓存)，内存的速度远不是硬盘能比的，硬盘就是SSD阵列也就是每秒百兆最快也就是G的级别。而内存已经达到数十G，双通道之后可以达到了上百G的级别。

缓存一次生产多次使用，避免每次读取都直接干到数据库。

如果说数据库主要是为了写，那么缓存主要是为了读，任务不同场景不同。

缓存能够带来性能的大幅提升，以memcache为例，单台memcache服务器简单的key-value查询能够达到TPS 5千以上，而redis服务器的话可以再翻倍达到10万以上没有问题的。

基本架构：

<div align="center"> <img src="../../pics/1570385922_79_w390.png" width="400"/> </div><br>



**更新频率低，读取频率高** 的数据才适合在数据库的前面使用缓存。

## 缓存雪崩（缓存故障大批量甚至整体查询都去数据库）

缓存雪崩：由于大量的热数据设置了相同或接近的过期时间导致缓存在某一时刻密集失效，或服务突然宕机。如果这个时间段内有大量请求，而查询数据量巨大，所有的请求都会达到存储层，存储层的调用量会暴增，引起数据库压力过大甚至宕机。

<div align="center"> <img src="../../pics/71fd9cc19e3b88c0bba149d2edce7996.jpg" width="500"/> </div><br>

Redis不可能把所有的数据都缓存起来(内存昂贵且有限)，所以Redis需要对数据设置过期时间，并采用的是惰性删除+定期删除两种策略对过期键删除。

如果缓存数据设置的过期时间是相同的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存同时失效，全部请求到数据库中。

**如何解决缓存雪崩？**

在缓存的时候给过期时间加上一个随机值，这样就会大幅度的减少缓存在同一时间过期。打散key的淘汰时间来尽量规避，但是不能彻底规避。

- 不同的过期时间：设置不同的过期时间，让缓存失效的时间点尽量均匀。
- 服务高可用：服务有可能挂掉，多增加几台 缓存实例，（一主多从或者多主多从），这样一台挂掉之后其他的还可以继续工作，实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。

- 集群：只是采用主从模式是不够的的。
- 设置本地缓存(ehcache/go-cache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
- 限流+服务降级：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量，对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。死一个服务总比全死强，丢掉一部分总比全丢强。

- 数据预热：数据加热的含义就是在正式部署之前，先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的 key。

在 redis 中，实现 高可用 的技术主要包括 持久化、复制、哨兵 和 集群，下面简单说明它们的作用，以及解决了什么样的问题：

持久化：持久化是 最简单的 高可用方法。它的主要作用是 数据备份，即将数据存储在 硬盘，保证数据不会因进程退出而丢失。

复制：复制是高可用 redis 的基础，哨兵 和 集群 都是在 复制基础 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。

哨兵：在复制的基础上，哨兵实现了 自动化 的 故障恢复。缺陷是 写操作 无法 负载均衡，存储能力受到单机的限制。

集群：通过集群，redis 解决了 写操作 无法 负载均衡以及存储能力 受到 单机限制 的问题，实现了较为完善的高可用方案。

## 缓存穿透(查根本不存在的数据)

缓存穿透：缓存和数据库中都没有的数据，这样每次请求都会去查库，不会查缓存，如果同一时间有大量请求进来的话，就会给数据库造成巨大的查询压力，甚至击垮db系统。

比如说查询id为-1的商品，这样的id在商品表里肯定不存在，如果没做特殊处理的话，攻击者很容易可以让系统奔溃。

<div align="center"> <img src="../../pics/5950897a85de5b08e4a394a3254b2f48.jpg" width="500"/> </div><br>

**如何解决缓存穿透？**

- 缓存空对象，避免无效Key的查询：指一个请求发送过来，如果此时缓存中和数据库都不存在这个请求所要查询的相关信息，那么数据库就会返回一个空对象，并将这个空对象和请求关联起来存到缓存中，当下次还是这个请求过来的时候，这时缓存就会命中，就直接从缓存中返回这个空对象，这样可以减少访问数据库的压力，提高当前数据库的访问性能。处理流程如下图

  <div align="center"> <img src="../../pics/16218402257616.png" width="500"/> </div><br>

  这种方法会存在两个问题：

  - 如果有大量的key穿透，缓存空对象会占用宝贵的内存空间（一般会将空对象设置一个较短的过期时间）。
  - 空对象的key设置了过期时间，这段时间内可能数据库刚好有了该key的数据，从而导致数据不一致的情况。

  这种情况下，我们可以用更好的解决方案，也就是**布隆过滤器**

- 由于请求的参数是不合法的(每次都请求不存在的参数)，可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，记录key是否存在，不合法就不让这个请求到数据库层。

  - 布隆过滤器：由一个长度为m比特的位数组（bit array）与k个哈希函数（hash function）组成的数据结构。原理是当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就大约知道集合中有没有它了，也就是说，**如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。**

    至于说为什么都是1的情况只是可能存在检索元素，这是因为不同的元素计算的哈希值有可能一样，会出现哈希碰撞，导致一个不存在的元素有可能对应的比特位为1。举个例子：下图是一个布隆过滤器，共有18个比特位，3个哈希函数。当查询某个元素w时，通过三个哈希函数计算，发现有一个比特位的值为0，可以肯定认为该元素不在集合中。

    <div align="center"> <img src="../../pics/20210524161420.png" width="500"/> </div><br>

    优点：

    - 节省空间：不需要存储数据本身，只需要存储数据对应hash比特位
    - 时间复杂度低：基于哈希算法来查找元素，插入和查找的时间复杂度都为O(k)，k为哈希函数的个数

    缺点：

    - 准确率有误：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数
    - 不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这样进一步导致了不存在的元素也会显示1的情况。

    **适用场景**

    - 爬虫系统url去重
    - 垃圾邮件过滤
    - 黑名单

  - **提高布隆过滤器的准确率：**

    1. 哈希函数的好坏
    2. 存储空间大小
    3. 哈希函数个数

    hash 函数的设计也是一个十分重要的问题，对于好的 hash 函数能大大降低布隆过滤器的误判率。同时，对于一个布隆过滤器来说，如果其位数组越大的话，那么每个 key 通过 hash 函数映射的位置会变得稀疏许多，不会那么紧凑，有利于提高布隆过滤器的准确率。同时，对于一个布隆过滤器来说，如果 key 通过许多 hash 函数映射，那么在位数组上就会有许多位置有标志，这样当用户查询的时候，在通过布隆过滤器来找的时候，误判率也会相应降低。

- id最大才999999 但可能传过来的id是9999991，9999992，9999993。。。既合法又不重复其实没有的数据id，那要怎么办？你可能会想到一直维护一个maxId，每次update数据库都要维护一下，那就成本太高了。这就要涉及到频控（最好外加服务降级），比如ip的维度等等，不管是不是恶意都要控制到可靠的范围内，这样才能比较可靠。

## 缓存击穿（高频次查刚失效的缓存）

缓存击穿：某个 key 经常被查询，或者这个 key 在缓存的过期时间失效的时候或者这是个冷门 key 时，这时候突然有大量有关这个 key 的访问请求，这样会导致大并发请求直接穿透缓存，请求数据库，瞬间对数据库的访问压力增大。

**归纳起来：造成缓存击穿的原因有两个。**

（1）一个 “冷门”key，突然被大量用户请求访问。

（2）一个 “热门”key，在缓存中时间恰好过期，这时有大量用户来进行访问。

<div align="center"> <img src="../../pics/16218407125094.png" width="500"/> </div><br>

**解决方案**

- 将高频次的热点数据设置为永远不过期。如全局配置，挡在最前面即便没了缓存也是不应该查询数据库的，直接抛出错误返回。

  这里的“永远不过期”包含两层意思：

  > (1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
  > (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

  从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。

  ```java
  String get(final String key) {  
          V v = redis.get(key);  
          String value = v.getValue();  
          long timeout = v.getTimeout();  
          if (v.timeout <= System.currentTimeMillis()) {  
              // 异步更新后台异常执行  
              threadPool.execute(new Runnable() {  
                  public void run() {  
                      String keyMutex = "mutex:" + key;  
                      if (redis.setnx(keyMutex, "1")) {  
                          // 3 min timeout to avoid mutex holder crash  
                          redis.expire(keyMutex, 3 * 60);  
                          String dbValue = db.get(key);  
                          redis.set(key, dbValue);  
                          redis.delete(keyMutex);  
                      }  
                  }  
              });  
          }  
          return value;  
      }  
  ```

- 常用基于Redis或者Zookeeper实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该key访问数据。对于 key 过期的时候，当 key 要查询数据库的时候加上一把锁，这时只能让第一个请求进行查询数据库，然后把从数据库中查询到的值存储到缓存中，对于剩下的相同的 key，可以直接从缓存中获取即可。

  如果我们是在单机环境下：直接使用常用的锁即可（如：Lock、Synchronized 等），在分布式环境下我们可以使用分布式锁，如：基于数据库、基于 Redis 或者 zookeeper 的分布式锁。

  缺点：当缓存失效的时候，同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量。这种情况该如何处理呢？只能说没什么设计是完美的，你又想数据一致，又想保证吞吐量，哪有那么好的事，为了系统能更加健全，必要的时候牺牲下性能也是可以采取的措施，两者之间怎么取舍要根据实际业务场景来决定，万能的技术方案什么的根本不存在。

  ```go
  String get(String key) {  
     String value = redis.get(key);  
     if (value  == null) {  
      if (redis.setnx(key_mutex, "1")) {  
          // 3 min timeout to avoid mutex holder crash  
          redis.expire(key_mutex, 3 * 60)  
          value = db.get(key);  
          redis.set(key, value);  
          redis.delete(key_mutex);  
      } else {  
          //其他线程休息50毫秒后重试  
          Thread.sleep(50);  
          get(key);  
      }  
    }  
  } 
  ```
  
  <div align="center"> <img src="../../pics/16218408302449.png" width="500"/> </div><br>

- "提前"使用互斥锁(mutex key)

  在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：

  ```java
  v = rediscache.get(key);  
  if (v == null) {  
      if (rediscache.setnx(key_mutex, 3 * 60 * 1000) == true) {  
          value = db.get(key);  
          rediscache.set(key, value);  
          rediscache.delete(key_mutex);  
      } else {  
          sleep(50);  
          retry();  
      }  
  } else {  
      if (v.timeout <= now()) {  
          if (rediscache.setnx(key_mutex, 3 * 60 * 1000) == true) {  
              // extend the timeout for other threads  
              v.timeout += 3 * 60 * 1000;  
              rediscache.set(key, v, KEY_TIMEOUT * 2);  
    
              // load the latest value from db  
              v = db.get(key);  
              v.timeout = KEY_TIMEOUT;  
              rediscache.set(key, value, KEY_TIMEOUT * 2);  
              rediscache.delete(key_mutex);  
          } else {  
              sleep(50);  
              retry();  
          }  
      }  
  }
  ```

- 资源保护

  采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。

**四种方案对比（没有最好，只有最合适）：**

   作为一个并发量较大的互联网应用，我们的目标有3个:

1. 加快用户访问速度，提高用户体验。

2. 降低后端负载，保证系统平稳。

3. 保证数据“尽可能”及时更新(要不要完全一致，取决于业务，而不是技术。)

| 解决方案                     | 优点                                                   | 缺点                                                         |
| ---------------------------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 简单分布式锁(Tim yang)       | 1. 思路简单2. 保证一致性                               | 1. 代码复杂度增大2. 存在死锁的风险3. 存在线程池阻塞的风险    |
| 加另外一个过期时间(Tim yang) | 1. 保证一致性                                          | 同上                                                         |
| 不过期(本文)                 | 1. 异步构建缓存，不会阻塞线程池                        | 1. 不保证一致性。2. 代码复杂度增大(每个value都要维护一个timekey)。3. 占用一定的内存空间(每个value都要维护一个timekey)。 |
| 资源隔离组件hystrix(本文)    | 1. hystrix技术成熟，有效保证后端。2. hystrix监控强大。 | 1. 部分访问存在降级策略。                                    |

**当然在请求刚进来的时候，也需要做好多处理：**

在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。



## 缓存预热

缓存预热就是系统上线后，先将相关的数据构建到缓存中，这样就可以避免用户请求的时候直接查库。

这部分预热的数据主要取决于访问量和数据量大小，如果数据的访问量不大的话，那么就没必要做预热，都没什么多少请求了，直接按正常的缓存读取流程执行就好。

访问量大的话，也要看数据的大小来做预热措施。

- 数据量不大的时候，工程启动的时候进行加载缓存动作，这种数据一般可以是电商首页的运营位之类的信息；
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存，并且确保访问期间不能更改缓存，比如用定时器在秒杀活动前30分钟就把商品信息之类的刷新到缓存，同时规定后台运营人员不能在秒杀期间更改商品属性。

## 缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。

在项目实战中通常会将部分热点数据缓存到服务的内存中，类似HashMap、Guava这样的工具，一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。

当然，这样的操作对于业务是有损害的，分布式系统中很容易就出现数据不一致的问题，所以，一般这种情况下，我们都优先保证从运维角度确保缓存服务器的高可用性，比如Redis的部署采用集群方式，同时做好备份，总之，尽量避免出现降级的影响。

## 缓存爆满（由于预估不足，内存设置不足，内存使用占满）

redis的淘汰策略算法有6种：

volatile-lru：从设置了过期时间的数据集中，选择最近最久未使用的数据释放。
allkeys-lru：从数据集中(包括设置过期时间以及未设置过期时间的数据集中)，选择最近最久未使用的数据释放。
volatile-random：从设置了过期时间的数据集中，随机选择一个数据进行释放。
allkeys-random：从数据集中(包括了设置过期时间以及未设置过期时间)随机选择一个数据进行入释放。
volatile-ttl：从设置了过期时间的数据集中，选择马上就要过期的数据进行释放操作。
noeviction：不删除任意数据(但redis还会根据引用计数器进行释放),这时如果内存不够时，会直接返回错误。

其实很多时候拿redis当mysql去用了，很多时候都是不失效的。这就导致了redis使用内存一直暴涨，如果内存设置的不够大那就有严重的问题了。

解决预案（其实不能叫解决方法）：

a。监控！监控！监控！其实即便不是这个问题也是需要对redis整体监控的，内存吃紧的时候尽早知晓！

b。集群也是要分开的。不是说一个集群大家一股脑的混在一起去用，一个爆掉全部爆掉。分开存储也是未来容易拆分迁移，可以细分。有些redis的key确实需要持久的可以一起存储，有些业务缓存有失效期可以一起存储，或者可以根据微服务模块的方式隔离存储。

c。随时准备好扩容，比如采用云redis集群。尽量不要自建集群，维护起来成本比较高。

## 网卡打满（缓存故障大批量甚至整体查询都去数据库）

一些核心数据比如全局的设置等等，这些大部分的请求都是需要获取的。这样会造成流量过于集中，达到物理网卡上限，从而导致redis的服务整体不稳定了：延迟长，请求超时，最后整体服务瘫了。

**怎么发现热key** 

- 凭借业务经验，进行预估哪些是热key.其实这个方法还是挺有可行性的。比如某商品在做秒杀，那这个商品的key就可以判断出是热key。缺点很明显，并非所有业务都能预估出哪些key是热key。

- 在客户端进行收集:在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。

- 在Proxy层做收集:有些集群架构是下面这样的，Proxy可以是Twemproxy，是统一的入口。可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。

- 用redis自带命令

  - monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。

  - hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。

- 抓包评估：redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性。

**解决方法**：

- 发现不对了赶紧做的是限流和服务降级，丢掉一部分请求先保证部分功能和请求的正常。

- 后期把这些key单独放到一个实例(库)里面，做好集群。

- 投机取巧的方式：每个业务服务器上部署一个redis做从机，做到缓存的分级。高频次访问的全局设置直接可以读本机的redis从机，因为这种全局配置肯定会有值哪怕默认值绝对不会为空。从机有问题或者读不到再去读取集群。

- 最主要的是架构师的预估，对自身业务要心里有谱，就在设计的架构的时候就做好隔离，等到病了再想去吃药有点晚了。







**总结一般架构图：**

<div align="center"> <img src="../../pics/16218432406863.png" width="700"/> </div><br>

