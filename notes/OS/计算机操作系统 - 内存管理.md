<!-- GFM-TOC -->

* [连续式内存分配](#连续式内存分配)
* [非连续内存分配](#非连续内存分配)
* [分页系统地址映射](#分页系统地址映射)
* [虚拟内存](#虚拟内存)
* [页面置换算法](#页面置换算法)
    * [1. 最佳](#1-最佳)
    * [2. 最近最久未使用](#2-最近最久未使用)
    * [3. 最近未使用](#3-最近未使用)
    * [4. 先进先出](#4-先进先出)
    * [5. 第二次机会算法](#5-第二次机会算法)
    * [6. 时钟](#6-时钟)
* [分段](#分段)
* [分页（主流方式）](分页（主流方式）)
* [段页式](#段页式)
* [分页与分段的比较](#分页与分段的比较)
<!-- GFM-TOC -->

# 连续式内存分配

## 1. 计算机体系结构及内存分层体系

<div align="center"> <img src="../../pics/ad7d9ecb-10ac-4c9d-b0fc-61ee11a2bf74.png" width="500px"/> </div><br>

<div align="center"> <img src="../../pics/9ca9d312-514d-4cce-b2b0-4dfa2d6cfcfe.png" width="500px"/> </div><br>
- 结构简要说明

  1、CPU：Central Process Unit中央处理器单元，即CPU属于处理器。

  2、CPU中有寄存器，因此寄存器的速度最快！内存、外存统称为CPU的“外存”。**寄存器**（Register）是[中央处理器](https://zh.wikipedia.org/wiki/中央處理器)内用来暂存指令、[数据](https://zh.wikipedia.org/wiki/數據)和[地址](https://zh.wikipedia.org/wiki/内存地址)的[电脑存储器](https://zh.wikipedia.org/wiki/電腦記憶體)。寄存器的存贮容量有限，读写速度非常快。在[计算机体系结构](https://zh.wikipedia.org/wiki/電腦架構)里，寄存器存储在已知时间点所作计算的中间结果，通过快速地访问数据来加速[计算机程序](https://zh.wikipedia.org/wiki/電腦程式)的运行。而且CPU只与寄存器中进行存取。而寄存器的数据又来源于内存。于是  CPU<--->寄存器<----->内存  这就是它们之间的信息交换。因为如果老是操作内存中的同一址地的数据，就会影响速度。于是就在寄存器与内存之间设置一个缓存。

  - [同样都是晶体管存储设备，为什么寄存器比内存快呢？](http://www.ruanyifeng.com/blog/2013/10/register.html)

    - **距离不同**

      内存离CPU比较远，所以要耗费更长的时间读取。以3GHz的CPU为例，电流每秒钟可以振荡30亿次，每次耗时大约为0.33[纳秒](http://en.wikipedia.org/wiki/Nanosecond)。光在1纳秒的时间内，可以前进30厘米。也就是说，在CPU的一个[时钟周期](http://zh.wikipedia.org/wiki/时钟频率)内，光可以前进10厘米。因此，如果内存距离CPU超过5厘米，就不可能在一个时钟周期内完成数据的读取，这还没有考虑硬件的限制和电流实际上达不到光速。相比之下，寄存器在CPU内部，当然读起来会快一点。

    - **硬件设计不同**

      内存的设计相对简单，每个位就是一个电容和一个晶体管，而寄存器的[设计](http://en.wikipedia.org/wiki/Register_file#Array)则完全不同，多出好几个电子元件。并且通电以后，寄存器的晶体管一直有电，而内存的晶体管只有用到的才有电，没用到的就没电，这样有利于省电。这些设计上的因素，决定了寄存器比内存读取速度更快。

    - **工作方式不同**

      寄存器的工作方式很简单，只有两步：

      （1）找到相关的位，（2）读取这些位。

      内存的工作方式就要复杂得多：

      （1）找到数据的指针。（指针可能存放在寄存器内，所以这一步就已经包括寄存器的全部工作了。）

      （2）将指针送往[内存管理单元](http://zh.wikipedia.org/wiki/内存管理单元)（MMU），由MMU将虚拟的内存地址翻译成实际的物理地址。

      （3）将物理地址送往内存控制器（[memory controller](http://en.wikipedia.org/wiki/Memory_controller)），由内存控制器找出该地址在哪一根内存插槽（bank）上。

      （4）确定数据在哪一个内存块（chunk）上，从该块读取数据。

      （5）数据先送回内存控制器，再送回CPU，然后开始使用。

      内存的工作流程比寄存器多出许多步。每一步都会产生延迟，累积起来就使得内存比寄存器慢得多。

      为了缓解寄存器与内存之间的巨大速度差异，硬件设计师做出了许多努力，包括在CPU内部设置[缓存](http://zh.wikipedia.org/wiki/CPU缓存)、优化CPU工作方式，尽量一次性从内存读取指令所要用到的全部数据等等。

  3、高速缓存是存放在CPU中的，它是介于CPU与内存知己的，以缓解它们之间速度不匹配的矛盾，使得内存访问CPU的时候较快。

  4、缓存是指在内存中划分出一块区域用于存放常使用的输入输出数据，以缓解CPU与外设处理速度不匹配的问题。

  5、CPU与（内存、外存）是不同的概念，CPU是一个独立的概念，而（内存、外存）是指对存储器的划分，内存的速度较外存的速度快，并且内存具有“掉电信息全部消失”的特性，而外存则具有“掉电信息也不会丢失”的特性。
- 操作系统在内存管理要完成的目标

  - [ ] 抽象：逻辑地址空间
  - [ ] 保护：独立地址空间
  - [ ] 共享：访问相同内存
  - [ ] 虚拟化：更多的地址空间

- 操作系统实现内存管理目标的手段

  程序重定位;分段;分页;虚拟内存（它使得[应用程序](https://baike.baidu.com/item/应用程序/5985445)认为它拥有连续的可用的[内存](https://baike.baidu.com/item/内存/103614)（一个连续完整的[地址空间](https://baike.baidu.com/item/地址空间/1423980)），而实际上，它通常是被分隔成多个[物理内存](https://baike.baidu.com/item/物理内存/2502263)碎片，还有部分暂时存储在外部[磁盘存储器](https://baike.baidu.com/item/磁盘存储器/2386684)上，在需要时进行[数据交换](https://baike.baidu.com/item/数据交换/1586256)。目前，大多数[操作系统](https://baike.baidu.com/item/操作系统/192)都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等）;按需分页虚拟内存

## 2.地址空间与地址生成

物理地址空间：硬件支持的地址空间。即加载到内存地址寄存器中的地址，内存单元的真正地址。在前端总线上传输的内存地址都是物理内存地址，编号从0开始一直到可用物理内存的最高端。这些数字被北桥(Nortbridge chip)映射到实际的内存条上。物理地址是明确的、最终用在总线上的编号，不必转换，不必分页，也没有特权级检查(no translation, no paging, no privilege checks)。

逻辑地址空间：一个运行的程序所拥有的内存范围。即程序中的段地址，逻辑地址由两部份组成，段标识符和段内[偏移量](https://baike.baidu.com/item/偏移量)，CPU所生成的地址。逻辑地址是内部和编程使用的、并不唯一。例如，你在进行C语言指针编程中，可以读取指针变量本身值(&操作)，实际上这个值就是逻辑地址，它是相对于你当前进程数据段的地址（偏移地址），不和绝对物理地址相干。

<div align="center"> <img src="../../pics/25e3e5ef-e9e9-41e1-a54e-b5c2fb3834e4.png" width="500px"/> </div><br>

<div align="center"> <img src="../../pics/9cffa352-b1e9-41c7-a6d2-cbc99e1cfb7f.png" width="500px"/> </div><br>

- 应用程序的逻辑地址是如何映射到物理地址

  <div align="center"> <img src="../../pics/b0f46760-c39a-4909-8431-cb6effcb5251.png" width="500px"/> </div><br>
<div align="center"> <img src="../../pics/25e3e5ef-e9e9-41e1-a54e-b5c2fb3834e4.png" width="500"/> </div><br>

<div align="center"> <img src="../../pics/9cffa352-b1e9-41c7-a6d2-cbc99e1cfb7f.png" width="500"/> </div><br>

- 应用程序的逻辑地址是如何映射到物理地址

  <div align="center"> <img src="../../pics/b0f46760-c39a-4909-8431-cb6effcb5251.png" width="500"/> </div><br>

  =>CPU方面

  a.运算器ALU需要在逻辑地址的内存内容(CPU要逻辑地址)

  b.内存管理单元MMU寻找在逻辑地址和物理地址之间的映射(然后MMU找逻辑和物理地址的关系)

  c. 控制器从总线发送在物理地址的内存内容的请求(关系找到后，去找对应物理地址)

  =>内存方面

  e.内存发送物理地址内存内容给CPU(物理地址找到了，给CPU)

  =>操作系统方面

  f.建立逻辑地址和物理地址之间的映射(确保程序不相互干扰)

<div align="center"> <img src="../../pics/fd4fca60-6363-4b46-997f-ada2101d4488.png" width="500px"/> </div><br>
## 3.连续内存分配：内存碎片与分区的动态分配

- 内存碎片问题：空闲内存不能被利用

  外部碎片：在分配单元间的未使用内存

  内部碎片：在分配单元中的未使用内存

- 简单的内存管理方法：

  当一个程序准许运行在内存中时，分配一个连续的区间

  分配一个连续的内存区间给运行的程序以访问数据

- 分区的动态分配策略

  - [ ] 首次适配：现在想分配n字节，从低地址开始找，碰到的第一个空间比n大的空闲块就使用它。

  <div align="center"> <img src="../../pics/2224c5c5-8fd4-4a62-9f14-9963ab5b25bb.png" width="500px"/> </div><br>

  - 要想实现首次分配，需要满足以下条件：

    需要存在一个按地址排序的空闲块列表

    分配需要找一个合适的分区

    重分配需要检查，看看自由分区能不能与相邻的空闲分区合并(形成更大的空闲块)，若有

  - 优点：简单；易于产生更大的空闲块，向着地址空间的结尾

  - 缺点：外部碎片的问题会加剧；不确定性

 

  - [ ] 最佳适配：为了分配n字节，使用最小的可用空闲块，以致块的尺寸比n大。

      <div align="center"> <img src="../../pics/7baf4934-c03c-4849-af2b-f9567eda8f39.png" width="500px"/> </div><br>

    - 目的：避免分割大的空闲块；最小化外部碎片产生的尺寸。
    
    - 要想实现最佳分配，需要满足以下条件：
    
      按尺寸排列的空闲列表
    
      分配需要寻找一个合适的分区
    
      重分配需要搜索和合并于相邻的空闲分区，若有
    
    - 优点：大部分分配是小尺寸时很有效；简单
    - 缺点：外部碎片；重分配慢；易产生很多没用的微小碎片。

  - [ ] 最差适配：为了分配n字节，使用最大的可用空闲块，以致块的尺寸比n大。

  <div align="center"> <img src="../../pics/65d514f1-6d25-4314-b7ac-ed3a37699bac.png" width="500px"/> </div><br>

    - 目的：避免太多的微小碎片
    
    - 要想实现最差分配，需要满足以下条件：
    
      按尺寸排列的空闲列表
    
      分配很快(获得最大的分区)
    
      重分配需要合并于相邻的空闲分区，若有，然后调整空闲块列表
    
    - 优点：假如分配时是中等尺寸效果最好
    - 缺点：重分配慢；外部碎片；易于破碎大的空闲块以至大分区不能被分割

## 4.连续内存分配：压缩式与交换式碎片整理

- 压缩式碎片整理(紧致)

  重制程序以合并孔洞

  要求所有程序是 动态可重置的

  问题：何时重置；开销。

- 交换式碎片整理

  运行程序需要更多的内存

  抢占等待的程序或回收它们的内存(把暂时不用的内容挪到磁盘里)

# 非连续内存分配

1. 非连续内存分配的优点：
   - 分配给一个程序的物理内存是非连续的
   - 更好的内存利用和管理
   - 允许共享代码和数据(共享库等)
   - 支持动态加载和动态链接

2. 非连续内存分配的缺点：
   - 如何建立虚拟（逻辑）地址和物理地址之间的转换：软件方案(开销大)；硬件方案
3. 硬件方案
   - 分段 Segmentation
   - 分页 Paging

## 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/22de0538-7c6e-4365-bd3b-8ce3c5900216.png"/> </div><br>

分段的做法是把每个表分成段（不同段按属性分离管理），一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。分段可以将内存更好的分离和共享。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png"/> </div><br>

如下图所示，逻辑地址空间是连续的，物理地址是离散的。

<div align="center"> <img src="../../pics/ab7b44c5-361b-4b14-ab51-40d66e70a7f6.png" width="500px"> </div><br>

以上开销大，如何用硬件实现：

- 段访问机制：一个段指一个“内存块”，是一个逻辑地址空间。

  程序根据段访问机制访问内存地址需要一个二维的二元组(s段号，addr端内偏移)

  <div align="center"> <img src="../../pics/1aa45772-a68c-4875-b66c-0d2f4b352865.png" width="500px"> </div><br>

- 段访问机制的硬件实现方案：

  <div align="center"> <img src="../../pics/a5c5d5bf-4cdc-4942-b618-d2b8c19495e3.png" width="500px"> </div><br>

## 分页（主流方式）

1. **分页的地址空间**

   划分物理内存至固定大小的帧

   > ->大小是2的幂，e.g.512，4096，8192

   -划分逻辑地址空间至相同大小的页

   > ->大小是2的幂，e.g.512，4096，8192

   -建立方案：转换逻辑地址为物理地址(pages to frames)

   > ->页表Page Table
   > ->MMU/TLB(快表)

2. **物理地址部分：页帧**

   页帧:物理内存被分割为大小相等的帧(物理地址部分)

   一个内存的物理地址是一个二元组(f,o)，f:帧号(它是F位的，因此意味着一共2F个帧)；o：帧内偏移(它是S位的，因此意味着每帧有2S字节)；物理地址=2^S x f + o。

   <div align="center"> <img src="../../pics/8fee3bc6-3ee2-45a8-8301-327e7eb99dad.png" width="500px"> </div><br>

首先有一个物理内存地址(3，6)，帧号是3，它是7位的，说明一共能有2^7个帧，这个帧是其中的第3个；
帧内偏移是6，他是9位的，说明一个帧里可以有2^9个字节，当前地址是在这个帧里的第6个字节；因此，它的物理地址是3 * 2^9 + 6。通过这个例子，可以发现 页帧号 的作用就是通过一个二元组能够找到一个物理地址。

3. **逻辑地址部分：页**

   页：一个程序的逻辑地址空间被划分为大小相等的页(逻辑地址部分)

   (逻辑地址的)页内偏移量=(物理地址的)帧内偏移量

   (逻辑地址的)页号大小可能不等于(物理地址的)帧号大小

   <div align="center"> <img src="../../pics/0f7b1465-dbc4-412c-bb2c-c59f29edbd7e.png" width="500px"> </div><br>

   通过这个例子，可以发现 页号 的作用就是通过一个二元组能够找到一个逻辑地址。页号和帧号不是相等。

   页寻址机制的实现：

   ​       页表实际上就是一个大的数组/hash表。它的index是 页号，对应的value是 页帧号，首先根据逻辑地址计算得到一个 页号，也就是index，再在页表中找到对应的 页帧号，最后根据 页帧号 计算得到物理地址；由于他们的页/帧内偏移相等，所以页表不需要保存这个数据。通过这种方式能够根据逻辑地址找到对应的物理地址。除此之外，还有一些flags标志位。

   <div align="center"> <img src="../../pics/85ceca9a-ee18-401c-9bad-1d6f0923c4ae.png" width="500px"> </div><br>

## 虚拟内存

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0\~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/7b281b1e-0595-402b-ae35-8c91084c33c1.png"/> </div><br>

## 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/cf4386a1-58c9-4eca-a17f-e12b1e9770eb.png" width="500"/> </div><br>

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 1. 最佳

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```html
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2. 最近最久未使用

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

```html
4，7，0，7，1，0，1，2，1，2，6
```

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/eb859228-c0f2-4bce-910d-d9f76929352b.png"/> </div><br>
### 3. 最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。

### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png"/> </div><br>

### 6. 时钟

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png"/> </div><br>

## 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

## 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。

- 地址空间的维度：分页是一维地址空间，分段是二维的。

- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。(硬件管理方便)

- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

